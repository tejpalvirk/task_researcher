# Required: Choose ONE provider or set up litellm proxy keys
ANTHROPIC_API_KEY="sk-ant-..."
GOOGLE_API_KEY="AIza..."
# OPENAI_API_KEY="sk-..." # If using OpenAI models via litellm

# Required for STORM research commands
# Select retriever ('bing', 'you', 'google', 'serper', 'tavily', etc. - see STORM docs)
STORM_RETRIEVER="bing"
BING_SEARCH_API_KEY="YOUR_BING_SEARCH_API_KEY"
# YDC_API_KEY="YOUR_YOUDOTCOM_API_KEY" # If using You.com
# TAVILY_API_KEY="..." # If using Tavily
# SERPER_API_KEY="..." # If using Serper

# Optional: Specify models (defaults will be used if not set)
LLM_MODEL="claude-3-5-sonnet-20240620" # Primary model for tasks, subtasks, analysis, etc.
BIG_STORM_MODEL="gemini-2.5-pro-exp-03-25"
SMALL_STORM_MODEL="gemini-2.0-flash"
STORM_EMBEDDING_MODEL="text-embedding-3-small" # Example embedding model for STORM VectorRM (if used)

# Optional: LLM parameters
MAX_TOKENS=4000
TEMPERATURE=0.7
SMALL_STORM_TEMP=0.7
BIG_STORM_TEMP=0.7

# Optional: STORM research depth/quality settings
STORM_SEARCH_TOP_K=5
STORM_MAX_TOKENS_CONV=500     # Max tokens for STORM conversation simulation
STORM_MAX_TOKENS_ARTICLE=3000 # Max tokens for STORM final article generation

# Optional: Task Researcher configuration
DEFAULT_SUBTASKS=3
DEFAULT_PRIORITY="medium"
PROJECT_NAME="Task Researcher Project"
PROJECT_VERSION="0.1.0"
TASKS_FILE_PATH="tasks/tasks.json"
COMPLEXITY_REPORT_PATH="scripts/task-complexity-report.json"
TASK_FILES_DIR="tasks"
STORM_OUTPUT_DIR="scripts/storm_research_output" # Directory for STORM generated files

# Logging
LOG_LEVEL="INFO" # DEBUG, INFO, WARNING, ERROR, CRITICAL
DEBUG="False"